{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Kanji with a time distributed MDN-RNN \n",
    "\n",
    "- This notebook is the same as the Kanji MDN-RNN except that it trains on predictions made over the whole sequence length.\n",
    "- The MDN-RNN is also written in Keras' functional API for good measure!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from context import * # imports the MDN layer \n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D \n",
    "%matplotlib inline\n",
    "\n",
    "# Only for GPU use:\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./kanji.rdp25.npz', <http.client.HTTPMessage at 0x7fa3e2847860>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train from David Ha's Kanji dataset from Sketch-RNN: https://github.com/hardmaru/sketch-rnn-datasets\n",
    "# Other datasets in \"Sketch 3\" format should also work.\n",
    "import urllib.request\n",
    "url = 'https://github.com/hardmaru/sketch-rnn-datasets/raw/master/kanji/kanji.rdp25.npz'  \n",
    "urllib.request.urlretrieve(url, './kanji.rdp25.npz')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset:\n",
    "\n",
    "Includes about 11000 handwritten kanji characters divied into training, validation, and testing sets.\n",
    "\n",
    "For creative purposes, we may not need the validation or testing sets, and can just focus on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training kanji: 10358\n",
      "Validation kanji: 600\n",
      "Testing kanji: 500\n"
     ]
    }
   ],
   "source": [
    "with np.load('./kanji.rdp25.npz') as data:\n",
    "    train_set = data['train']\n",
    "    valid_set = data['valid']\n",
    "    test_set = data['test']\n",
    "    \n",
    "print(\"Training kanji:\", len(train_set))\n",
    "print(\"Validation kanji:\", len(valid_set))\n",
    "print(\"Testing kanji:\", len(test_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup an MDN RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "inputs (InputLayer)          (None, 50, 3)             0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 50, 256)           266240    \n",
      "_________________________________________________________________\n",
      "lstm2 (LSTM)                 (None, 50, 256)           525312    \n",
      "_________________________________________________________________\n",
      "td_mdn (TimeDistributed)     (None, 50, 70)            17990     \n",
      "=================================================================\n",
      "Total params: 809,542\n",
      "Trainable params: 809,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Training Hyperparameters:\n",
    "SEQ_LEN = 50\n",
    "BATCH_SIZE = 64\n",
    "HIDDEN_UNITS = 256\n",
    "EPOCHS = 100\n",
    "SEED = 2345  # set random seed for reproducibility\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "OUTPUT_DIMENSION = 3\n",
    "NUMBER_MIXTURES = 10\n",
    "\n",
    "inputs = keras.layers.Input(shape=(SEQ_LEN,OUTPUT_DIMENSION), name='inputs')\n",
    "lstm1_out = keras.layers.LSTM(HIDDEN_UNITS, name='lstm1', return_sequences=True)(inputs)\n",
    "lstm2_out = keras.layers.LSTM(HIDDEN_UNITS, name='lstm2', return_sequences=True)(lstm1_out)\n",
    "mdn_out = keras.layers.TimeDistributed(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES, name='mdn_outputs'), name='td_mdn')(lstm2_out)\n",
    "\n",
    "model = keras.models.Model(inputs=inputs, outputs=mdn_out)\n",
    "model.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the Data and Train the Model\n",
    "\n",
    "- Chop up the data into slices of the correct length, generate `X` and `y` for the training process.\n",
    "- Very similar process to the previous RNN examples!\n",
    "- We end up with 330000 examples - a pretty healthy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:\n",
      "X: (154279, 50, 3)\n",
      "y: (154279, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Functions for slicing up data\n",
    "def slice_sequence_examples(sequence, num_steps):\n",
    "    xs = []\n",
    "    for i in range(len(sequence) - num_steps - 1):\n",
    "        example = sequence[i: i + num_steps]\n",
    "        xs.append(example)\n",
    "    return xs\n",
    "\n",
    "def seq_to_overlapping_format(examples):\n",
    "    \"\"\"Takes sequences of seq_len+1 and returns overlapping\n",
    "    sequences of seq_len.\"\"\"\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ex in examples:\n",
    "        xs.append(ex[:-1])\n",
    "        ys.append(ex[1:])\n",
    "    return (xs,ys)\n",
    "\n",
    "# Prepare training data as X and Y.\n",
    "slices = []\n",
    "for seq in train_set:\n",
    "    slices +=  slice_sequence_examples(seq, SEQ_LEN+1)\n",
    "X, y = seq_to_overlapping_format(slices)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print(\"Number of training examples:\")\n",
    "print(\"X:\", X.shape)\n",
    "print(\"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples:\n",
      "X: (8928, 50, 3)\n",
      "y: (8928, 50, 3)\n"
     ]
    }
   ],
   "source": [
    "# Prepare validation data as X and Y.\n",
    "slices = []\n",
    "for seq in valid_set:\n",
    "    slices +=  slice_sequence_examples(seq, SEQ_LEN+1)\n",
    "Xval, yval = seq_to_overlapping_format(slices)\n",
    "\n",
    "Xval = np.array(Xval)\n",
    "yval = np.array(yval)\n",
    "\n",
    "print(\"Number of training examples:\")\n",
    "print(\"X:\", Xval.shape)\n",
    "print(\"y:\", yval.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the training!\n",
    "\n",
    "- We're not going to train in the tutorial!\n",
    "- These settings take about 220 seconds per epoch, about 6 hours for the whole training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "filepath=\"kanji_mdnrnn-{epoch:02d}.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "callbacks = [keras.callbacks.TerminateOnNaN(), checkpoint, early_stopping]\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, validation_data=(Xval,yval))\n",
    "model.save('kanji_mdnrnn_model_time_distributed.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title(\"Kanji MDRNN Training\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out the model! Generate some Kanji!\n",
    "\n",
    "We need to create a decoding model with batch size 1 and sequence length 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (1, 1, 256)               266240    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1, 256)                  525312    \n",
      "_________________________________________________________________\n",
      "mdn_1 (MDN)                  (1, 70)                   17990     \n",
      "=================================================================\n",
      "Total params: 809,542\n",
      "Trainable params: 809,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Decoding Model\n",
    "# Same as training model except for dimension and mixtures.\n",
    "\n",
    "decoder = keras.Sequential()\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(1,1,OUTPUT_DIMENSION), return_sequences=True, stateful=True))\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, stateful=True))\n",
    "decoder.add(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "decoder.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "decoder.summary()\n",
    "\n",
    "#decoder.load_weights('kanji_mdnrnn_model_time_distributed.h5') # load weights independently from file\n",
    "#decoder.load_weights('kanji_mdnrnn-99.hdf5')\n",
    "decoder.load_weights('kanji_mdnrnn_model_time_distributed.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating drawings\n",
    "\n",
    "- First need some helper functions to view the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def zero_start_position():\n",
    "    \"\"\"A zeroed out start position with pen down\"\"\"\n",
    "    out = np.zeros((1, 1, 3), dtype=np.float32)\n",
    "    out[0, 0, 2] = 1 # set pen down.\n",
    "    return out\n",
    "\n",
    "def generate_sketch(model, start_pos, num_points=100):\n",
    "     return None\n",
    "\n",
    "def cutoff_stroke(x):\n",
    "    return np.greater(x,0.5) * 1.0\n",
    "\n",
    "def plot_sketch(sketch_array):\n",
    "    \"\"\"Plot a sketch quickly to see what it looks like.\"\"\"\n",
    "    sketch_df = pd.DataFrame({'x':sketch_array.T[0],'y':sketch_array.T[1],'z':sketch_array.T[2]})\n",
    "    sketch_df.x = sketch_df.x.cumsum()\n",
    "    sketch_df.y = -1 * sketch_df.y.cumsum()\n",
    "    # Do the plot\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    #ax1.scatter(sketch_df.x,sketch_df.y,marker='o', c='r', alpha=1.0)\n",
    "    # Need to do something with sketch_df.z\n",
    "    ax1.plot(sketch_df.x,sketch_df.y,'r-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVG Drawing Function\n",
    "\n",
    "Here's Hardmaru's Drawing Functions from _write-rnn-tensorflow_. Big hat tip to Hardmaru for this!\n",
    "\n",
    "Here's the source: https://github.com/hardmaru/write-rnn-tensorflow/blob/master/utils.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardmaru's Drawing Functions from write-rnn-tensorflow\n",
    "# Big hat tip\n",
    "# Here's the source:\n",
    "# https://github.com/hardmaru/write-rnn-tensorflow/blob/master/utils.py\n",
    "\n",
    "import svgwrite\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "def get_bounds(data, factor):\n",
    "    min_x = 0\n",
    "    max_x = 0\n",
    "    min_y = 0\n",
    "    max_y = 0\n",
    "\n",
    "    abs_x = 0\n",
    "    abs_y = 0\n",
    "    for i in range(len(data)):\n",
    "        x = float(data[i, 0]) / factor\n",
    "        y = float(data[i, 1]) / factor\n",
    "        abs_x += x\n",
    "        abs_y += y\n",
    "        min_x = min(min_x, abs_x)\n",
    "        min_y = min(min_y, abs_y)\n",
    "        max_x = max(max_x, abs_x)\n",
    "        max_y = max(max_y, abs_y)\n",
    "\n",
    "    return (min_x, max_x, min_y, max_y)\n",
    "\n",
    "def draw_strokes(data, factor=1, svg_filename='sample.svg'):\n",
    "    min_x, max_x, min_y, max_y = get_bounds(data, factor)\n",
    "    dims = (50 + max_x - min_x, 50 + max_y - min_y)\n",
    "\n",
    "    dwg = svgwrite.Drawing(svg_filename, size=dims)\n",
    "    dwg.add(dwg.rect(insert=(0, 0), size=dims, fill='white'))\n",
    "\n",
    "    lift_pen = 1\n",
    "\n",
    "    abs_x = 25 - min_x\n",
    "    abs_y = 25 - min_y\n",
    "    p = \"M%s,%s \" % (abs_x, abs_y)\n",
    "\n",
    "    command = \"m\"\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        if (lift_pen == 1):\n",
    "            command = \"m\"\n",
    "        elif (command != \"l\"):\n",
    "            command = \"l\"\n",
    "        else:\n",
    "            command = \"\"\n",
    "        x = float(data[i, 0]) / factor\n",
    "        y = float(data[i, 1]) / factor\n",
    "        lift_pen = data[i, 2]\n",
    "        p += command + str(x) + \",\" + str(y) + \" \"\n",
    "\n",
    "    the_color = \"black\"\n",
    "    stroke_width = 2\n",
    "\n",
    "    dwg.add(dwg.path(p).stroke(the_color, stroke_width).fill(\"none\"))\n",
    "\n",
    "    dwg.save()\n",
    "    display(SVG(dwg.tostring()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"244.18982567367752\" version=\"1.1\" width=\"159.97207010041976\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs/><rect fill=\"white\" height=\"244.18982567367752\" width=\"159.97207010041976\" x=\"0\" y=\"0\"/><path d=\"M73.16515202279237,25 m0.0,0.0 m-34.67354909397204,1.6999544679462064 l1.2270268001350046,6.5445035376313845 -0.5708425890942318,41.61957807495959 m-14.147787139861096,-25.999227374543576 l5.610492050199192,1.8445756139703013 7.456378154620832,0.9592931208009936 l24.281225921703257,-4.290794133981884 m-21.265233573015582,15.77353682626787 l5.208090429674627,2.65424867382075 6.121680655193215,1.7704861064460389 m10.450784149172987,-16.64599174091382 l10.678654603310228,0.6073467188547201 24.382424016040815,-2.2727920365529193 m-45.741715140888026,22.037427081526925 l8.254333858925236,-0.0579562789311176 m41.79251024423384,-13.429875840835967 l4.415989602919442,0.49634210130026013 2.437233870246526,1.1896038071869723 l0.7785985077187373,1.7786542713895621 -2.81454383862975,17.875032534731023 m-58.59165303633291,0.8483468664585445 l61.98871964988354,-5.593724498128884 m-57.70274329442421,-3.8456319077379466 l1.8743106493081076,2.7601238414062763 0.8507976282615768,3.313686246509133 l0.18245103553031433,33.08474490989249 1.3521355931901835,4.002305699881221 l3.217697336357727,3.0940797808091602 6.996763683309625,2.2681637124931324 l12.430605392889836,1.0338306139207825 25.997681746146338,0.03307595604957769 l17.231325008945625,-1.422613725860504 6.403611419741662,-2.37651581918968 l3.794351455087284,-3.762538676168176 1.8991123210994898,-6.118099452631576 m-65.70767495457584,-59.04070308379762 l8.373250545833612,3.2858953823897306 11.447602044767061,6.065352330193637 m-42.35245503345113,18.040315308838636 l10.927460660887606,5.430454927327993 8.656028457557388,5.41301652764957 m-10.676762714881848,5.065189525787988 l16.503196971949148,3.1289540919649115 7.659929891210453,3.6420219818203274 m-47.28641343233738,31.240316874273674 l6.71227594034642,0.5414302590154325 21.44210527169062,-2.809780673708531 l9.17185689782044,0.22263406412836897 m-17.404765197659028,3.703386695025114 l2.6528435454951005,4.719220170427025 0.25191967245783,42.76291623193676 m-20.559962161486624,-21.1292790194749 l2.6722719935009245,1.1802014652912376 4.892041933730098,-0.3474041470988909 l43.363149727153946,-10.204695047436674 m-3.5695881423062383,-19.86491016338829 l2.479148126423477,3.3371240575327645 1.8273539876741904,12.057539549142513 l1.968352406530112,16.48005304021596 m-10.051027127885208,-4.131630609052722 l2.776146690414147,2.3940681989973362 1.5225818195545688,1.1226672436536174 l1.1525695916238874,1.4012029092821388 m9.805245189377763,-3.8934176088059145 l0.20329037675582845,1.5852614453657528 -1.270937821096872,4.589417675239919 m-17.63311393448342,1.8121000205034652 l1.6513247870931977,2.0733619898605395 m-2.323064061244624,-11.52195798017885 l9.12907407479106,3.0362207092706517 7.8578296691859375,2.1381934995409773 m-4.387263822835018,3.5291824877832876 l1.8550041019330588,3.4620619446537213 m-0.628905464447897,4.260338557267909 l-0.5053915935844143,1.4119863630846663 -3.7802206127786624,5.134151173967034 m-14.822738611087157,-6.614431341803379 l1.4913206515137998,1.4036057024891502 0.13171697712446925,3.8286269872773535 m-13.299747677442307,2.789117518976471 l6.3006674852805284,-0.7083616666690149 12.591027923096728,-1.8495719876450167 l5.54842966046134,-0.3315682902591638 1.0683800071418665,0.4864742647690695 l0.4378514468981187,1.6661489259482662 -0.9584912624200326,15.423775801528873 l-0.7923447195273654,4.209539073850624 -0.8435920006144774,2.7917947495548 l-1.1058023992321888,1.3124693479632699 -2.09181404793987,0.4528108767777787 m-41.05879896823274,-13.667826320973932 l28.790319953604726,4.800734440737193 m-30.06105278119629,10.800174191796557 l37.24149108091147,-2.322857087672493 m-6.001720062933102,-49.66747457949144 l3.306675608792087,2.9371949109086666 1.797581060237075,3.181513260207713 l-0.00020853187087258723,49.540164697814994 -1.8878813282488678,7.6754249133929555 l-2.5588594191659824,3.2567098369310683 \" fill=\"none\" stroke=\"black\" stroke-width=\"2\"/></svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predict a character and plot the result.\n",
    "temperature = 1.5 # seems to work well with rather high temperature (2.5)\n",
    "sigma_temp = 0.01\n",
    "\n",
    "p = zero_start_position()\n",
    "sketch = [p.reshape(3,)]\n",
    "\n",
    "for i in range(100):\n",
    "    params = decoder.predict(p.reshape(1,1,3))\n",
    "    p = mdn.sample_from_output(params[0], OUTPUT_DIMENSION, NUMBER_MIXTURES, temp=temperature, sigma_temp=sigma_temp)\n",
    "    sketch.append(p.reshape((3,)))\n",
    "\n",
    "sketch = np.array(sketch)\n",
    "decoder.reset_states()\n",
    "\n",
    "sketch.T[2] = cutoff_stroke(sketch.T[2])\n",
    "draw_strokes(sketch, factor=0.5)\n",
    "#plot_sketch(sketch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
