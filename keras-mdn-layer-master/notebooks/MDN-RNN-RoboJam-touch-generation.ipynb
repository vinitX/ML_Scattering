{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Generating touch data in time: RoboJam\n",
    "\n",
    "- Let's look at some \"touch screen music\" data.\n",
    "- E.g., music made with the \"MicroJam\" app:\n",
    "\n",
    "![MicroJam Performance](https://media.giphy.com/media/XWIkHvErZtPG0/giphy.gif)\n",
    "\n",
    "These performances are sequences of x and y locations, as well as time!\n",
    "\n",
    "In MicroJam, you can \"reply\" to performances made by other users; but what if you don't have any friends??? (Too much time spent on Neural Networks). \n",
    "\n",
    "Let's make \"RoboJam\", a system to respond automatically to performances.\n",
    "\n",
    "- We need to predict x and y values---as well as time!\n",
    "- So, we use a 3 dimensional MDN-RNN.\n",
    "\n",
    "The idea is to generate \"responses\" to an existing touchscreen sequence. Here's some examples of what it will do:\n",
    "\n",
    "![Robojam Model Examples](https://preview.ibb.co/mpfa9T/robojam_examples.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Input\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "import h5py\n",
    "import random\n",
    "import time\n",
    "import pandas as pd\n",
    "from context import * # imports MDN\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "input_colour = 'darkblue'\n",
    "gen_colour = 'firebrick'\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for GPU use:\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "from keras import backend as K\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, download the dataset\n",
    "\n",
    "- This is a set of microjam performances collected from our lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download microjam performance data if needed.\n",
    "import urllib.request\n",
    "url = 'http://folk.uio.no/charlepm/datasets/TinyPerformanceCorpus.h5'\n",
    "urllib.request.urlretrieve(url, './TinyPerformanceCorpus.h5')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for touchscreen performances\n",
    "\n",
    "We need a few helper functions for managing performances:\n",
    "    \n",
    "- Convert performances to and from pandas dataframes.\n",
    "- Generate random touches.\n",
    "- Sample whole performances from scratch and from a priming performance.\n",
    "- Plot performances including dividing into swipes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 1\n",
    "\n",
    "def perf_df_to_array(perf_df, include_moving=False):\n",
    "    \"\"\"Converts a dataframe of a performance into array a,b,dt format.\"\"\"\n",
    "    perf_df['dt'] = perf_df.time.diff()\n",
    "    perf_df.dt = perf_df.dt.fillna(0.0)\n",
    "    # Clean performance data\n",
    "    # Tiny Performance bounds defined to be in [[0,1],[0,1]], edit to fix this.\n",
    "    perf_df.at[perf_df[perf_df.dt > 5].index, 'dt'] = 5.0\n",
    "    perf_df.at[perf_df[perf_df.dt < 0].index, 'dt'] = 0.0\n",
    "    perf_df.at[perf_df[perf_df.x > 1].index, 'x'] = 1.0\n",
    "    perf_df.at[perf_df[perf_df.x < 0].index, 'x'] = 0.0\n",
    "    perf_df.at[perf_df[perf_df.y > 1].index, 'y'] = 1.0\n",
    "    perf_df.at[perf_df[perf_df.y < 0].index, 'y'] = 0.0\n",
    "    if include_moving:\n",
    "        output = np.array(perf_df[['x', 'y', 'dt', 'moving']])\n",
    "    else:\n",
    "        output = np.array(perf_df[['x', 'y', 'dt']])\n",
    "    return output\n",
    "\n",
    "\n",
    "def perf_array_to_df(perf_array):\n",
    "    \"\"\"Converts an array of a performance (a,b,dt(,moving) format) into a dataframe.\"\"\"\n",
    "    perf_array = perf_array.T\n",
    "    perf_df = pd.DataFrame({'x': perf_array[0], 'y': perf_array[1], 'dt': perf_array[2]})\n",
    "    if len(perf_array) == 4:\n",
    "        perf_df['moving'] = perf_array[3]\n",
    "    else:\n",
    "        # As a rule of thumb, could classify taps with dt>0.1 as taps, dt<0.1 as moving touches.\n",
    "        perf_df['moving'] = 1\n",
    "        perf_df.at[perf_df[perf_df.dt > 0.1].index, 'moving'] = 0\n",
    "    perf_df['time'] = perf_df.dt.cumsum()\n",
    "    perf_df['z'] = 38.0\n",
    "    perf_df = perf_df.set_index(['time'])\n",
    "    return perf_df[['x', 'y', 'z', 'moving']]\n",
    "\n",
    "\n",
    "def random_touch(with_moving=False):\n",
    "    \"\"\"Generate a random tiny performance touch.\"\"\"\n",
    "    if with_moving:\n",
    "        return np.array([np.random.rand(), np.random.rand(), 0.01, 0])\n",
    "    else:\n",
    "        return np.array([np.random.rand(), np.random.rand(), 0.01])\n",
    "\n",
    "\n",
    "def constrain_touch(touch, with_moving=False):\n",
    "    \"\"\"Constrain touch values from the MDRNN\"\"\"\n",
    "    touch[0] = min(max(touch[0], 0.0), 1.0)  # x in [0,1]\n",
    "    touch[1] = min(max(touch[1], 0.0), 1.0)  # y in [0,1]\n",
    "    touch[2] = max(touch[2], 0.001)  # dt # define minimum time step\n",
    "    if with_moving:\n",
    "        touch[3] = np.greater(touch[3], 0.5) * 1.0\n",
    "    return touch\n",
    "\n",
    "\n",
    "def generate_random_tiny_performance(model, n_mixtures, first_touch, time_limit=5.0, steps_limit=1000, temp=1.0, sigma_temp=0.0, predict_moving=False):\n",
    "    \"\"\"Generates a tiny performance up to 5 seconds in length.\"\"\"\n",
    "    if predict_moving:\n",
    "        out_dim = 4\n",
    "    else:\n",
    "        out_dim = 3\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    previous_touch = first_touch\n",
    "    performance = [previous_touch.reshape((out_dim,))]\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        params = model.predict(previous_touch.reshape(1,1,out_dim) * SCALE_FACTOR)\n",
    "        previous_touch = mdn.sample_from_output(params[0], out_dim, n_mixtures, temp=temp, sigma_temp=sigma_temp) / SCALE_FACTOR\n",
    "        output_touch = previous_touch.reshape(out_dim,)\n",
    "        output_touch = constrain_touch(output_touch, with_moving=predict_moving)\n",
    "        performance.append(output_touch.reshape((out_dim,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    return np.array(performance)\n",
    "\n",
    "\n",
    "def condition_and_generate(model, perf, n_mixtures, time_limit=5.0, steps_limit=1000, temp=1.0, sigma_temp=0.0, predict_moving=False):\n",
    "    \"\"\"Conditions the network on an existing tiny performance, then generates a new one.\"\"\"\n",
    "    if predict_moving:\n",
    "        out_dim = 4\n",
    "    else:\n",
    "        out_dim = 3\n",
    "    time = 0\n",
    "    steps = 0\n",
    "    # condition\n",
    "    for touch in perf:\n",
    "        params = model.predict(touch.reshape(1, 1, out_dim) * SCALE_FACTOR)\n",
    "        previous_touch = mdn.sample_from_output(params[0], out_dim, n_mixtures, temp=temp, sigma_temp=sigma_temp) / SCALE_FACTOR\n",
    "        output = [previous_touch.reshape((out_dim,))]\n",
    "    # generate\n",
    "    while (steps < steps_limit and time < time_limit):\n",
    "        params = model.predict(previous_touch.reshape(1, 1, out_dim) * SCALE_FACTOR)\n",
    "        previous_touch = mdn.sample_from_output(params[0], out_dim, n_mixtures, temp=temp, sigma_temp=sigma_temp) / SCALE_FACTOR\n",
    "        output_touch = previous_touch.reshape(out_dim,)\n",
    "        output_touch = constrain_touch(output_touch, with_moving=predict_moving)\n",
    "        output.append(output_touch.reshape((out_dim,)))\n",
    "        steps += 1\n",
    "        time += output_touch[2]\n",
    "    net_output = np.array(output)\n",
    "    return net_output\n",
    "\n",
    "\n",
    "def divide_performance_into_swipes(perf_df):\n",
    "    \"\"\"Divides a performance into a sequence of swipe dataframes for plotting.\"\"\"\n",
    "    touch_starts = perf_df[perf_df.moving == 0].index\n",
    "    performance_swipes = []\n",
    "    remainder = perf_df\n",
    "    for att in touch_starts:\n",
    "        swipe = remainder.iloc[remainder.index < att]\n",
    "        performance_swipes.append(swipe)\n",
    "        remainder = remainder.iloc[remainder.index >= att]\n",
    "    performance_swipes.append(remainder)\n",
    "    return performance_swipes\n",
    "\n",
    "\n",
    "input_colour = \"#4388ff\"\n",
    "gen_colour = \"#ec0205\"\n",
    "\n",
    "def plot_perf_on_ax(perf_df, ax, color=\"#ec0205\", linewidth=3, alpha=0.5):\n",
    "    \"\"\"Plot a 2D representation of a performance 2D\"\"\"\n",
    "    swipes = divide_performance_into_swipes(perf_df)\n",
    "    for swipe in swipes:\n",
    "        p = ax.plot(swipe.x, swipe.y, 'o-', alpha=alpha, markersize=linewidth)\n",
    "        plt.setp(p, color=color, linewidth=linewidth)\n",
    "    ax.set_ylim([1.0,0])\n",
    "    ax.set_xlim([0,1.0])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "def plot_2D(perf_df, name=\"foo\", saving=False, figsize=(5, 5)):\n",
    "    \"\"\"Plot a 2D representation of a performance 2D\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(figsize))\n",
    "    plot_perf_on_ax(perf_df, ax, color=gen_colour, linewidth=5, alpha=0.7)\n",
    "    if saving:\n",
    "        fig.savefig(name+\".png\", bbox_inches='tight')\n",
    "\n",
    "def plot_double_2d(perf1, perf2, name=\"foo\", saving=False, figsize=(8, 8)):\n",
    "    \"\"\"Plot two performances in 2D\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(figsize))\n",
    "    plot_perf_on_ax(perf1, ax, color=input_colour, linewidth=5, alpha=0.7)\n",
    "    plot_perf_on_ax(perf2, ax, color=gen_colour, linewidth=5, alpha=0.7)\n",
    "    if saving:\n",
    "        fig.savefig(name+\".png\", bbox_inches='tight')\n",
    "        \n",
    "# fig, ax = plt.subplots(figsize=(5, 5))\n",
    "# plot_perf_on_ax(perf_array_to_df(p), ax, color=\"#ec0205\", linewidth=4, alpha=0.7)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load up the Dataset:\n",
    "\n",
    "The dataset consists of around 1000 5-second performances from the MicroJam app.\n",
    "\n",
    "This is in a sequence of points consisting of an x-location, a y-location, and a time-delta from the previous point.\n",
    "\n",
    "When the user swipes, the time-delta is very small, if they tap it's quite large.\n",
    "\n",
    "Let's have a look at some of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "microjam_data_file_name = \"./TinyPerformanceCorpus.h5\"\n",
    "\n",
    "with h5py.File(microjam_data_file_name, 'r') as data_file:\n",
    "    microjam_corpus = data_file['total_performances'][:]\n",
    "\n",
    "print(\"Corpus data points between 100 and 120:\")\n",
    "print(perf_array_to_df(microjam_corpus[100:120]))\n",
    "\n",
    "print(\"Some statistics about the dataset:\")\n",
    "pd.DataFrame(microjam_corpus).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This time, the X and Y locations are *not* differences, but the exact value, but the time is a delta value.\n",
    "- The data doesn't have a \"pen up\" value, but we can just call taps with dt>0.1 as taps, dt<0.1 as moving touches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a bit of the data to have a look:\n",
    "plot_2D(perf_array_to_df(microjam_corpus[100:200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MDN RNN\n",
    "\n",
    "- Now we're going to build an MDN-RNN to predict MicroJam data.\n",
    "- The architecture will be:\n",
    "    - 3 inputs (x, y, dt)\n",
    "    - 2 layers of 256 LSTM cells each\n",
    "    - MDN Layer with 3 dimensions and 5 mixtures.\n",
    "    - Training model will have a sequence length of 30 (prediction model: 1 in, 1 out)\n",
    "    \n",
    "![RoboJam MDN RNN Model](https://preview.ibb.co/cKZk9T/robojam_mdn_diagram.png)\n",
    "    \n",
    "- Here's the model parameters and training data preparation. \n",
    "- We end up with 172K training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Hyperparameters:\n",
    "SEQ_LEN = 30\n",
    "BATCH_SIZE = 256\n",
    "HIDDEN_UNITS = 256\n",
    "EPOCHS = 100\n",
    "VAL_SPLIT=0.15\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "SEED = 2345  \n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "def slice_sequence_examples(sequence, num_steps):\n",
    "    xs = []\n",
    "    for i in range(len(sequence) - num_steps - 1):\n",
    "        example = sequence[i: i + num_steps]\n",
    "        xs.append(example)\n",
    "    return xs\n",
    "\n",
    "def seq_to_singleton_format(examples):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for ex in examples:\n",
    "        xs.append(ex[:-1])\n",
    "        ys.append(ex[-1])\n",
    "    return (xs,ys)\n",
    "\n",
    "sequences = slice_sequence_examples(microjam_corpus, SEQ_LEN+1)\n",
    "print(\"Total training examples:\", len(sequences))\n",
    "X, y = seq_to_singleton_format(sequences)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"X:\", X.shape, \"y:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's set up the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIMENSION = 3\n",
    "NUMBER_MIXTURES = 5\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(None,SEQ_LEN,OUTPUT_DIMENSION), return_sequences=True))\n",
    "model.add(keras.layers.LSTM(HIDDEN_UNITS))\n",
    "model.add(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "model.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "- Now we do the training\n",
    "    - batch size of 256\n",
    "    - 100 epochs.\n",
    "- This takes about 110s per epoch on Google Colab (3 hours to train)\n",
    "\n",
    "Here's the training and validation loss from my training run:\n",
    "\n",
    "![Training and validation loss](figures/robojam-mdn-loss.png)\n",
    "\n",
    "- The validation loss (in green) tends to jump around a lot in the early epochs.\n",
    "- The training loss (in blue) has one strange jump around epoch 15, but then reduces quickly at about epoch 20.\n",
    "- Seems to still be learning, could probably improve this model further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "# Define callbacks\n",
    "filepath=\"robojam_mdrnn-E{epoch:02d}-VL{val_loss:.2f}.h5\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, save_weights_only=True, verbose=1, save_best_only=True, mode='min')\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "callbacks = [keras.callbacks.TerminateOnNaN(), checkpoint, early_stopping]\n",
    "\n",
    "history = model.fit(X, y, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=callbacks, validation_split=VAL_SPLIT)\n",
    "\n",
    "# Save the Model\n",
    "model.save('robojam-mdrnn.h5')  # creates a HDF5 file of the model\n",
    "\n",
    "# Plot the loss\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try out the model\n",
    "\n",
    "- Let's try out the model\n",
    "- First we will load up a decoding model with a sequence length of 1.\n",
    "- The weights are loaded from a the trained model file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding Model\n",
    "decoder = keras.Sequential()\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, batch_input_shape=(1,1,OUTPUT_DIMENSION), return_sequences=True, stateful=True))\n",
    "decoder.add(keras.layers.LSTM(HIDDEN_UNITS, stateful=True))\n",
    "decoder.add(mdn.MDN(OUTPUT_DIMENSION, NUMBER_MIXTURES))\n",
    "decoder.compile(loss=mdn.get_mixture_loss_func(OUTPUT_DIMENSION,NUMBER_MIXTURES), optimizer=keras.optimizers.Adam())\n",
    "decoder.summary()\n",
    "\n",
    "# decoder.set_weights(model.get_weights())\n",
    "decoder.load_weights(\"robojam-mdrnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting some conditioned performances.\n",
    "\n",
    "This model seems to work best with a very low temperature for sampling from the Gaussian elements (`sigma_temp=0.05`) and a temperature for choosing between mixtures (pi-temperature) of around 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length = 100\n",
    "t = random.randint(0,len(microjam_corpus)-length)\n",
    "ex =  microjam_corpus[t:t+length]  #sequences[600]\n",
    "\n",
    "decoder.reset_states()\n",
    "p = condition_and_generate(decoder, ex, NUMBER_MIXTURES, temp=1.5, sigma_temp=0.05)\n",
    "plot_double_2d(perf_array_to_df(ex), perf_array_to_df(p), figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also generate unconditioned performances from a random starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder.reset_states()\n",
    "t = random_touch()\n",
    "p = generate_random_tiny_performance(decoder, NUMBER_MIXTURES, t, temp=1.2, sigma_temp=0.01)\n",
    "plot_2D(perf_array_to_df(p), figsize=(4,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RoboJam in Practice!\n",
    "\n",
    "- RoboJam is designed for use in a mobile music called MicroJam!\n",
    "- Check it out on the iTunes App Store (only Apple devices! Soz!)\n",
    "- [microjam website: https://microjam.info](https://microjam.info)\n",
    "\n",
    "![RoboJam in action](https://preview.ibb.co/hXg43o/robojam_action_diagram.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
